services:
  # Qdrant Vector Database - Shared by all services
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    healthcheck:
      test:
        - CMD-SHELL
        - bash -c ':> /dev/tcp/127.0.0.1/6333' || exit 1
      interval: 5s
      timeout: 5s
      retries: 3
    restart: unless-stopped
    networks:
      - app-network

  # Langfuse - LLM Observability Platform
  langfuse-db:
    image: postgres:15-alpine
    container_name: langfuse-db
    environment:
      - POSTGRES_DB=langfuse
      - POSTGRES_USER=langfuse
      - POSTGRES_PASSWORD=langfuse
    volumes:
      - langfuse_db_data:/var/lib/postgresql/data
    restart: unless-stopped
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U langfuse"]
      interval: 10s
      timeout: 5s
      retries: 5

  langfuse:
    image: langfuse/langfuse:2
    container_name: langfuse
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=postgresql://langfuse:langfuse@langfuse-db:5432/langfuse
      - NEXTAUTH_URL=http://localhost:3000
      - NEXTAUTH_SECRET=${LANGFUSE_NEXTAUTH_SECRET:-langfuse-local-secret-change-in-production}
      - SALT=${LANGFUSE_SALT:-langfuse-local-salt-change-in-production}
      - TELEMETRY_ENABLED=false
    depends_on:
      langfuse-db:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Backend API
  backend:
    build:
      context: ./backend-py
      dockerfile: Dockerfile
    container_name: backend
    ports:
      - "8000:8000"
    environment:
      - LLM_PROVIDER=${LLM_PROVIDER:-google}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - GOOGLE_MODEL=${GOOGLE_MODEL:-gemini-2.5-flash}
      - GOOGLE_SAFETY_THRESHOLD=${GOOGLE_SAFETY_THRESHOLD:-BLOCK_MEDIUM_AND_ABOVE}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      - EMBEDDING_PROVIDER=${EMBEDDING_PROVIDER:-sentence_transformers}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-sentence-transformers/all-MiniLM-L6-v2}
      - QDRANT_URL=http://qdrant:6333
      - LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY}
      - LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY}
      - LANGFUSE_HOST=${LANGFUSE_HOST:-http://langfuse:3000}
      - LANGFUSE_ENABLED=${LANGFUSE_ENABLED:-false}
      - PORT=8000
      - DEBUG=true
    depends_on:
      qdrant:
        condition: service_healthy
    volumes:
      # Mount code for development (comment out for production)
      - ./backend-py/app:/app/app
      - ./backend-py/main.py:/app/main.py
      - ./backend-py/run.py:/app/run.py
    restart: unless-stopped
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s

  # Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: frontend
    ports:
      - "80:80"
    depends_on:
      - backend
    restart: unless-stopped
    networks:
      - app-network
    environment:
      - BACKEND_URL=http://backend:8000
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:80/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Ingest Service (runs once to populate vector database)
  ingest:
    build:
      context: ./ingest
      dockerfile: Dockerfile
    container_name: ingest
    environment:
      - QDRANT_URL=http://qdrant:6333
      - QDRANT_API_KEY=${QDRANT_API_KEY}
      - QDRANT_COLLECTION=${QDRANT_COLLECTION:-planes_gobierno}
      - EMBEDDING_PROVIDER=${EMBEDDING_PROVIDER:-sentence_transformers}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-sentence-transformers/all-MiniLM-L6-v2}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - DATA_DIR=/app/data
    depends_on:
      qdrant:
        condition: service_healthy
    volumes:
      - ./ingest/data:/app/data
      - ./ingest/qdrant_storage:/app/qdrant_storage
    networks:
      - app-network
    # This service will run and exit, or remove 'command' below to keep it running
    entrypoint: ["python", "main.py"]
    restart: "no"

volumes:
  qdrant_data:
    driver: local
  langfuse_db_data:
    driver: local

networks:
  app-network:
    driver: bridge
